# Proyecto Final MLOps: IntegraciÃ³n Supervisada, No Supervisada y OrquestaciÃ³n

Este proyecto representa la culminaciÃ³n del curso de Machine Learning, implementando un pipeline `end-to-end` robusto que integra ingenierÃ­a de datos, aprendizaje no supervisado (Clustering) y modelos supervisados avanzados, todo orquestado automÃ¡ticamente.

**Asignatura:** MLY0100 - Machine Learning
**Integrantes:**
* Jorge Garrido


---

## 1. Objetivos del Proyecto

El sistema analiza el comportamiento de compra de clientes para resolver dos problemas predictivos, utilizando una arquitectura moderna de MLOps:

1.  **ClasificaciÃ³n:** Predecir la **CategorÃ­a de Producto** (`category`) que comprarÃ¡ un cliente.
2.  **RegresiÃ³n:** Predecir el **Monto Total** (`total_amount`) de la transacciÃ³n.

---

## 2. Arquitectura TÃ©cnica (Stack MLOps)

La soluciÃ³n utiliza un stack tecnolÃ³gico avanzado para garantizar reproducibilidad y escalabilidad:

* **Kedro:** Framework principal para la estructuraciÃ³n de pipelines modulares.
    * *Pipeline `dp`:* Procesamiento y limpieza de datos.
    * *Pipeline `ul`:* **Aprendizaje No Supervisado** (K-Means, DBSCAN, Hierarchical, PCA, t-SNE).
    * *Pipeline `int`:* IntegraciÃ³n y entrenamiento del modelo final.
* **Apache Airflow:** Orquestador de tareas. Gestiona la ejecuciÃ³n secuencial y dependencias de los pipelines mediante un DAG maestro.
* **Docker & Docker Compose:** Infraestructura como cÃ³digo. Levanta servicios independientes para la Base de Datos (Postgres), el Webserver de Airflow, el Scheduler y el entorno de ejecuciÃ³n de Python.
* **DVC (Data Version Control):** Versionado de datasets, modelos (`.pkl`) y mÃ©tricas, asegurando la trazabilidad de los experimentos.

---

## 3. MetodologÃ­a de Ciencia de Datos

### A. Fase No Supervisada (Feature Engineering Avanzado)
Para mejorar la capacidad predictiva, se implementaron tÃ©cnicas de agrupamiento y reducciÃ³n de dimensionalidad:
* **Clustering:** Se utilizaron algoritmos como **K-Means (k=5)**, **DBSCAN** y **Clustering JerÃ¡rquico** para segmentar a los clientes en perfiles de comportamiento.
* **ReducciÃ³n:** Se aplicÃ³ **PCA** y **t-SNE** para analizar la varianza y estructura de los datos.
* **DetecciÃ³n de AnomalÃ­as:** Se implementÃ³ **Isolation Forest** para identificar transacciones atÃ­picas.

### B. Fase de IntegraciÃ³n (Supervisado "Supercharged")
Los clusters generados y los features temporales (Edad, Mes, DÃ­a) se inyectaron como nuevas variables predictivas (*features*) en un modelo de **Random Forest**.

---

## 4. Resultados y Comparativa (Ev2 vs Ev3)

Gracias a la integraciÃ³n del aprendizaje no supervisado y la optimizaciÃ³n de features, se logrÃ³ un incremento drÃ¡stico en el rendimiento del modelo.

### Tabla Comparativa de ClasificaciÃ³n (Accuracy)

| Etapa | Modelo | Accuracy | Estado |
| :--- | :--- | :--- | :--- |
| **EvaluaciÃ³n 2** | RegresiÃ³n LogÃ­stica (Baseline) | 30.80% | âŒ Insuficiente |
| **EvaluaciÃ³n 3** | **Random Forest + Clustering** | **83.41%** | âœ… **Ã‰xito (+52.6%)** |

**ConclusiÃ³n del AnÃ¡lisis:**
El modelo original (Ev2) carecÃ­a de informaciÃ³n suficiente para distinguir patrones complejos. La segmentaciÃ³n de clientes mediante Clustering y la inclusiÃ³n de atributos granulares del producto permitieron al modelo Random Forest capturar la lÃ³gica de compra con alta precisiÃ³n.

---

## 5. Instrucciones de EjecuciÃ³n (Despliegue)

El proyecto estÃ¡ completamente contenerizado. Para ejecutar el sistema completo (Airflow + Pipelines):

**Prerrequisitos:**
* Docker Desktop instalado y corriendo.

**Pasos:**

1.  Clonar el repositorio y entrar a la carpeta de Docker:
    ```bash
    cd proyecto-ml-final/docker
    ```

2.  Levantar la infraestructura con Docker Compose:
    ```bash
    docker-compose up --build
    ```
    *(Esperar a que inicien los servicios postgres, webserver y scheduler).*

3.  Acceder a la interfaz de Airflow:
    * **URL:** [http://localhost:8080](http://localhost:8080)
    * **Usuario:** `admin`
    * **ContraseÃ±a:** `admin`

4.  Ejecutar el Pipeline Maestro:
    * Buscar el DAG **`proyecto_final_mlops_v3`**.
    * Activar el interruptor (**ON**) y hacer clic en **Trigger DAG** (Play â–¶ï¸).
    * Observar en la vista "Graph" cÃ³mo se ejecutan secuencialmente: `Data Processing` -> `Unsupervised Learning` -> `Model Integration`.

---

**Estado del Proyecto:** Finalizado y Funcional. ðŸš€
